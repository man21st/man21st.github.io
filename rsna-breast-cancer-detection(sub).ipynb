{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\n!pip install -q /kaggle/input/rsna-bcd-whl-ds/python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -q /kaggle/input/rsna-bcd-whl-ds/pylibjpeg-1.4.0-py3-none-any.whl\n!pip install -q /kaggle/input/rsna-bcd-whl-ds/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n!cp -r /kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle /tmp/ && pip install -q /tmp/efficientnet_kaggle\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:38:32.561256Z","iopub.execute_input":"2023-03-05T19:38:32.561743Z","iopub.status.idle":"2023-03-05T19:40:07.579464Z","shell.execute_reply.started":"2023-03-05T19:38:32.561698Z","shell.execute_reply":"2023-03-05T19:40:07.577523Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0mcp: cannot stat '/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport tqdm\nimport dicomsdl as dicom\n","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:40:07.582729Z","iopub.execute_input":"2023-03-05T19:40:07.583317Z","iopub.status.idle":"2023-03-05T19:40:07.590733Z","shell.execute_reply.started":"2023-03-05T19:40:07.583253Z","shell.execute_reply":"2023-03-05T19:40:07.589342Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ntest = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\ntrain.head()\ntrain = train[[col for col in train.columns if col in ['site_id',\n 'patient_id',\n 'image_id',\n 'laterality',\n 'view',\n 'age',\n 'implant',\n 'machine_id',\n 'prediction_id','cancer']]]\ntrain.loc[train['age'].isnull(),'age'] = train['age'].mean()\n\npath = os.path.join('/kaggle/input/rsna-breast-cancer-detection/train_images')\nlist_dir = os.listdir(path)\nk =[]\ny={}\nmlo_path_l = []\ncc_path_l = []\nmlo_path_r = []\ncc_path_r = []\nfor i, sub in tqdm.tqdm(enumerate(list_dir)):\n    for j, fname in enumerate(os.listdir(os.path.join(path,sub))):\n        view = (train.loc[train['image_id']==int(((fname).split('.'))[0]),'view'].values)[0]\n        laterality = (train.loc[train['image_id']==int(((fname).split('.'))[0]),'laterality'].values)[0]\n        cancer = int(train.loc[train['image_id']==int(((fname).split('.'))[0]),'cancer'])\n        k.append(os.path.join(os.path.join(path,sub),fname))\n        y[int(((fname).split('.'))[0])] = cancer\n        if view =='MLO':\n            if laterality=='L':\n                 mlo_path_l.append(os.path.join(os.path.join(path,sub),fname))\n            else:\n                mlo_path_r.append(os.path.join(os.path.join(path,sub),fname))\n        elif view =='CC':\n            if laterality=='L':\n                 cc_path_l.append(os.path.join(os.path.join(path,sub),fname))\n            else:\n                cc_path_r.append(os.path.join(os.path.join(path,sub),fname))\nmlo_path_dict_l={}\nfor i in range(len(list(mlo_path_l))):\n    mlo_path_dict_l[i] = mlo_path_l[i]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-05T19:40:07.592765Z","iopub.execute_input":"2023-03-05T19:40:07.593121Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"11455it [01:07, 174.85it/s]","output_type":"stream"}]},{"cell_type":"markdown","source":"tf.config.run_functions_eagerly(True)\n@tf.function\ndef gen(x):\n    i = path_dict[x]\n    image = (dicom.open(i).pixelData(storedvalue=True))\n    max_val = tf.cast(image[-1,1000],dtype=tf.float32)\n    #print(max_val)\n    la = dict_path[i]\n    \n    #if  train[train['image_id']==int(i.split('/')[-1].split('.')[0])]['laterality'].values[0]=='L':\n    if la == 'L':\n        if max_val>=1000:\n            return (max_val-tf.image.resize(tf.expand_dims(image[100:-100,:2500],axis=-1),[150,100],preserve_aspect_ratio=False))/255.0\n        else:\n            return (tf.image.resize(tf.expand_dims(image[100:-100,:2500],axis=-1),[150,100],preserve_aspect_ratio=False)/255.0)\n    elif la == 'R':\n        if max_val>=1000:\n            return (max_val-tf.image.resize(tf.image.flip_left_right\n(tf.expand_dims(image[100:-100,:2500],axis=-1)),[150,100],preserve_aspect_ratio=False))/255.0\n        else:\n            return (tf.image.resize(tf.image.flip_left_right\n(tf.expand_dims(image[100:-100,:2500],axis=-1)),[150,100],preserve_aspect_ratio=False)/255.0)\n      #  if max_val>=1000:\n      #      return ((max_val-tf.image.resize_with_pad(tf.image.flip_left_right(tf.expand_dims(image,axis=-1)),500,500))/255.0)[:,140:-60,0],(y[int(i.split('/')[-1].split('.')[0])])\n      #  else:\n       #     return (tf.image.resize_with_pad(tf.image.flip_left_right(tf.expand_dims(image,axis=-1)),500,500)/255.0)[:,140:-60,0],(y[int(i.split('/')[-1].split('.')[0])])\n\n\n\n# Create a TensorFlow dataset and map your function to it\ndataset= tf.data.Dataset.from_tensor_slices(np.arange((len(list(path_list)))))\ndataset = dataset.map(lambda x: tf.numpy_function(gen, inp=[x], Tout=(tf.float32))).batch(1)                ","metadata":{"execution":{"iopub.status.busy":"2023-03-05T17:20:02.233006Z","iopub.execute_input":"2023-03-05T17:20:02.233383Z","iopub.status.idle":"2023-03-05T17:20:02.280256Z","shell.execute_reply.started":"2023-03-05T17:20:02.233322Z","shell.execute_reply":"2023-03-05T17:20:02.278623Z"}}},{"cell_type":"code","source":"def pfbeta_fast(labels, predictions, beta=1):\n\n    pTP = tf.math.reduce_sum(labels * predictions)\n    pFP = tf.math.reduce_sum((1-labels) * predictions)\n    num_positives = tf.math.reduce_sum((labels))  #  = pTP+pFN\n\n    pPrecision = pTP/(pTP+pFP)\n    pRecall = pTP/num_positives\n\n    beta_squared = beta**2\n\n    if (pPrecision > 0 and pRecall > 0):\n        pF1 = (1+beta_squared) * pPrecision * pRecall/(beta_squared*pPrecision + pRecall)\n        return pF1\n    else:\n        return 0.0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef mylayer(X,f,size,s,how='same',a=1):\n    layer = tf.keras.layers.Conv2D(filters=f,kernel_size=size,strides=s,padding=how)(X)\n    layer = tf.keras.layers.BatchNormalization()(layer)\n    if a ==1:\n        layer = tf.keras.layers.Activation('relu')(layer)\n    else:\n        layer +=0\n    return layer\ndef add_layer(X_prev,X):\n    added = tf.keras.layers.Add()([X_prev,X])\n    return added\ndef conv_connect(X_prev,X,f,s,how='same'):\n    layer = tf.keras.layers.Conv2D(filters=f,kernel_size=(1,1),strides=2,padding=how)(X_prev)\n    layer = tf.keras.layers.ZeroPadding2D((7,7))(layer)\n    layer = tf.keras.layers.BatchNormalization()(layer)\n    layer = add_layer(layer,X)\n    layer = tf.keras.layers.Activation('relu')(layer)\n    return layer\n\ndef cnn():\n    \n    \n    pre = tf.keras.applications.convnext.ConvNeXtSmall(\n    model_name='convnext_small',\n    include_top=False,\n    include_preprocessing=True,\n    weights=None,\n    input_shape=(150,100,3),pooling='avg')\n    pre.load_weights('/kaggle/input/naidu-cancer-comp/convnext_small_notop.h5')\n    pre.trainable=True\n    \n    for layer in pre.layers[:-20]:\n        layer.trainable=False\n    inputs = tf.keras.Input(shape=(150,100,1))\n    X = tf.keras.layers.Concatenate()([inputs for i in range(3)])\n    X = pre(X)\n    #X = tf.keras.layers.Dropout(0.20)(X)\n    outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(X)\n    model = tf.keras.Model(inputs=inputs,outputs=outputs)\n    model.summary()\n    model.compile(loss='BinaryCrossentropy',optimizer = tf.keras.optimizers.Adam(),metrics=['accuracy',pfbeta_fast])\n    return model\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\nmodel = cnn()\nmodel.load_weights('/kaggle/input/naidu-cancer-comp/mlo_l_10e.h5')\n#model.fit(mlo_dataset,verbose=True,epochs=7,callbacks=[tf.keras.callbacks.ModelCheckpoint('model.h5')])\n ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub = test[['image_id','view','laterality','patient_id','prediction_id']]\ntest_sub['path'] =0\nfor i in range(len(test_sub)):\n    test_sub.loc[i,'path'] = '/kaggle/input/rsna-breast-cancer-detection/test_images/{}/{}.dcm'.format(str(test_sub.iloc[i,3]),str(test_sub.iloc[i,0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,path in enumerate(test_sub['path']):\n    image_id = path.split('/')[-1]\n    sub = test_sub[test_sub['path']==path]#['laterality'].values[0]\n    patient_id = path.split('/')[-2]\n    if sub['laterality'].values[0] =='L':\n        image = (dicom.open(path).pixelData(storedvalue=True))\n        max_val = tf.cast(image[-1,1000],dtype=tf.float32)\n        if max_val >=1000:\n            image = (max_val-tf.image.resize(tf.expand_dims(image[100:-100,:2500],axis=-1),[150,100],preserve_aspect_ratio=False))/255.0\n            test_sub.loc[i,'cancer']=model.predict(tf.expand_dims(image,0))[0,0]\n        else:\n            image = (max_val-tf.image.resize(tf.expand_dims(image[100:-100,:2500],axis=-1),[150,100],preserve_aspect_ratio=False))/255.0\n            test_sub.loc[i,'cancer']=model.predict(tf.expand_dims(image,0))[0,0]\n            \n    else:\n        image = ((dicom.open(path).pixelData(storedvalue=True)))\n        max_val = tf.cast(image[-1,1000],dtype=tf.float32)\n        if max_val >=1000:\n            image = (max_val-tf.image.resize(tf.image.flip_left_right(tf.expand_dims(image,axis=-1))[100:-100,:2500,:],[150,100],preserve_aspect_ratio=False))/255.0\n            test_sub.loc[i,'cancer']=model.predict(tf.expand_dims(image,0))[0,0]\n        else:\n            image = (tf.image.resize(tf.image.flip_left_right(tf.expand_dims(image,axis=-1))[100:-100,:2500,:],[150,100],preserve_aspect_ratio=False))/255.0\n            test_sub.loc[i,'cancer']=model.predict(tf.expand_dims(image,0))[0,0]\n        \n        \n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = ((test_sub.groupby(['prediction_id'])[['prediction_id','cancer']].sum()>0.5).astype('int').reset_index())\nsubmission.to_csv('submission.csv',index=False)\nsubmission\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}